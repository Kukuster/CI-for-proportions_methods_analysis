from collections import defaultdict
from decimal import Decimal

from numpy import float64, longdouble, mean as np_mean, array as np_array
from tqdm.std import trange
from lib.CI_efficacy import CI_method_efficacy, NoCoverageException, plot_styles
from lib.data_functions import float_to_str
from lib.math_functions import binomial_distribution_two_tailed_range, get_binomial_z_precision, normal_z_score_two_tailed
from typing import Callable, Iterable, List, Literal, Tuple, Union, TypedDict
from numpy.random import binomial as binomial_experiment
from scipy.stats import binom as binomial_distribution
from matplotlib import pyplot as plt


"""CI method for proportions"""
CI_method_for_proportion = Callable[
    [int, int, float],
    Tuple[float, float]
]

proportion_type = Union[str, float, Decimal]

# This is how dictionary type is defined
class proportions_type_range_named(TypedDict):
    start: proportion_type
    end: proportion_type
    step: proportion_type

proportions_type_range = Tuple[proportion_type, proportion_type, proportion_type]

proportions_type_list = Union[List[float], List[float64]]


class CI_method_for_proportion_efficacy(CI_method_efficacy):
    """A toolkit for studying efficacy of a CI method for the proportion.

    Parameters
    ----------
    method : CI_method
        a method for calculating CI for the proportion

    method_name : str
        a human-readable name of the method.

    Attributes
    ----------
    method : CI_method
        a method for calculating CI for the proportion

    method_name : str
        a human-readable name of the method.

    confidence : float
        A number between 0 and 1.
        Confidence interval - coverage that you want to get.

    sample_size : int
        Total number of trials in the sample

    proportions : List[np.float64]
        A list of true proportions to try.

    coverage : np.ndarray
        1d array, np.longdouble, values between 0 and 100
        Coverage represents a proportion of cases that fall under the confidence interval produced
        by the given `method` for a particular proportion from the given list.
        User can assess the efficacy of a CI method by comparing these values to the `confidence`.

    average_coverage : np.longdouble
        average of all values in `coverage`

    average_deviation : np.longdouble
        average of all values in `coverage`

    figure : matplotlib.figure.Figure
        a matplotlib figure that's being generated by plotting the `coverage`

    """

    def __init__(self, method: CI_method_for_proportion, method_name: str):
        self._method: CI_method_for_proportion = method
        self._method_name: str = method_name


    @property
    def proportions(self):
        return self._proportions

    @proportions.setter
    def proportions(self, value: Iterable[float64]):
        value = list(value)
        if not all([0 <= p <= 1 for p in value]): raise ValueError(
            f"any true population proportion can only be a real value between 0 and 1")
        if len(value) == 0: raise ValueError(
            f"list of proportions has to have at least 1 value")
        self._proportions = list(value)


    @property
    def coverage(self):
        return self._coverage

    @coverage.setter
    def coverage(self, value: List[longdouble]):
        self._coverage = value
        self._average_coverage: longdouble = np_mean(value, dtype=longdouble)
        self._average_deviation: longdouble = np_mean(
            abs(np_array(value) - (self.confidence*100)), dtype=longdouble)


    @property
    def average_coverage(self) -> longdouble:
        return self._average_coverage


    @property
    def average_deviation(self) -> longdouble:
        return self._average_deviation



    def calculate_coverage_randomly(self,
                                    sample_size: int,
                                    proportions: Iterable[float64],
                                    confidence: float,
                                    n_of_experiments: int = 20000
                                    ):
        """
        Calculates actual coverage of confidence interval for given desired *confidence*
        for a given specific *sample_size* and list of *proportions*
        using a specified number of random binomial experiments: *n_of_experiments*
        """
        """
        Calculates true coverage of confidence interval for proportion
        produced by the `method` for the given desired `confidence` using a simulation
        with a number of random experiments (`n_of_experiments`).

        Total number of trials in a sample is `sample_size`.

        Proportion for the sample is taken from the list `proportions`,
        producing a list of results for each proportion.

        This list is `coverage`, and is saved to `self.coverage`.
        """
        self.confidence = confidence
        self.proportions = list(proportions)
        self.sample_size = sample_size

        if __debug__ is True:
            print(f"""CI_method = "{self.method_name}", calculation_method = random simulation,
n = {sample_size}, ps[{len(self.proportions)}] = ({self.proportions[0]}...{self.proportions[-1]},d={float(Decimal(str(self.proportions[1]))-Decimal(str(self.proportions[0])))}),
confidence = {float_to_str(self.confidence*100)}%, n_of_experiments = {n_of_experiments}""")

        coverage = []

        # The return value of this function will be cached (this is not necessary)
        z = normal_z_score_two_tailed(p=confidence)

        # this will be the maximum length of str representation of any proportion
        p_str_len = max(len(str(self.proportions[0])),
                        len(str(self.proportions[1])),
                        len(str(self.proportions[-1])))
        # 2 more chars than the `confidence` str representation is enough for displaying coverage
        cov_str_len_total = max(len(str(self.confidence))+2, 5)
        # 3 characters are reserved: 2 for tens and units, 1 for point
        cov_str_len_afterpoint = max(cov_str_len_total-3, 2)

        progress_bar_str = "p={} => cov={}%"
        t = trange(len(self.proportions),
                   desc=progress_bar_str.format("***", "***"))
        for i in t:
            prob = self.proportions[i]

            x = binomial_experiment(sample_size, prob, n_of_experiments)
            CIs = [self.method(x[j], sample_size, confidence) for j in range(0, n_of_experiments)]

            covered = [int(CI[0] < prob < CI[1]) for CI in CIs]

            # multiplied by 100 in-place for better progress bar, and for a better figure later
            thiscoverage = (sum(covered)/n_of_experiments) * 100

            coverage.append(thiscoverage)

            t.set_description(progress_bar_str.format(
                f"{prob:{p_str_len}}",
                f"{thiscoverage:{cov_str_len_total}.{cov_str_len_afterpoint}f}"))

        self.coverage = coverage
        t.set_description(progress_bar_str.format(
            "*", "*", f"{self.average_coverage:{cov_str_len_total}.{cov_str_len_afterpoint}f}"))
        print(f"average confidence level {self.average_coverage:{cov_str_len_total}.{cov_str_len_afterpoint}f}")
        print(f"average deviation from {float_to_str(self.confidence*100)}% = {self.average_deviation:{cov_str_len_total}.{cov_str_len_afterpoint}f} (coverage %)")
        print("")
        return self.coverage


    def calculate_coverage_analytically(self,
                                    sample_size: int,
                                    proportions: Iterable[float64],
                                    confidence: float,
                                    z_precision: Union[float, Literal['auto']] = 'auto'
                                    ):
        """
        Calculates true coverage of confidence interval for proportion
        produced by the `method` for the given desired `confidence` using
        an indistinguishably precise approximation for the analytical solution.

        Optimal approximation precision is auto-picked for the specific case,
        but can be set manually in `z_precision`. This is a z-value for precision instead of p.
        Meaning, `z_precision` of 1.96 is 95% precision (which is a terrible precision).

        Total number of trials in a sample is `sample_size`.

        Proportion for the sample is taken from the list `proportions`,
        producing a list of results for each proportion.

        This list is `coverage`, and is saved to `self.coverage`.
        """
        self.confidence = confidence
        self.proportions = list(proportions)
        self.sample_size = sample_size

        if z_precision == 'auto':
            z_precision = get_binomial_z_precision(confidence)

        if __debug__ is True:
            print(f"""CI_method = "{self.method_name}", calculation_method = analytical approximation,
n = {sample_size}, ps[{len(self.proportions)}] = ({self.proportions[0]}...{self.proportions[-1]},d={float(Decimal(str(self.proportions[1]))-Decimal(str(self.proportions[0])))}),
confidence = {float_to_str(self.confidence*100)}%, z_precision = {z_precision:5.2f}""")

        coverage = []

        # The return value of this function will be cached (this is not necessary)
        z = normal_z_score_two_tailed(p=confidence)

        # this will be the maximum length of str representation of any proportion
        p_str_len = max(len(str(self.proportions[0])),
                        len(str(self.proportions[1])),
                        len(str(self.proportions[-1])))
        # 2 more chars than the `confidence` str representation is enough for displaying coverage
        cov_str_len_total = max(len(str(self.confidence))+2, 5)
        # 3 characters are reserved: 2 for tens and units, 1 for point
        cov_str_len_afterpoint = max(cov_str_len_total-3, 2)

        progress_bar_str = "p={} => cov={}%"
        t = trange(len(self.proportions),
                   desc=progress_bar_str.format("***", "***"))
        for i in t:
            prob = self.proportions[i]

            """The entire range of a binomial distribution could be used"""
            #x_from, x_to = (0, sample_size)
            """
            But this is too computationally expensive to calculate CI for `y` value of each `x`
            of a binomial distribution.
            Since most `y` values of the binomial distribution are very close to zero,
            we can use only a small part of the binomial distribution around the peak.
            Such part of a binomial distribution can often be efficiently modeled
            with a normal distribution.

            Let's say we need to consider the span covering 99.999% percent of the mass
            of the binomial distribution. According to the normal distribution, this would be
            a range that spans 4.42 standard deviations from the mean on both sides.
            Given a somewhat conservative implementation of the algorithm, we could say that
            this would almost certainly cover at least 99.999% of a binomial distribution
            `Binom(n,p)` for most values of `n` and `p`.

            Let's assume we need:
            for 95% confidence         => 99.995%         of the distribution
            for 99% confidence         => 99.999%         of the distribution
            for 99.9% confidence       => 99.9999%        of the distribution
            for 99.99% confidence      => 99.999_99%      of the distribution
            for significant range of 5 sigma:
            for 99.999_943% confidence => 99.999_999_943% of the distribution
            etc.

            This, precision is to be determined given the confidence. General formula:
            p_precision = 1-((1-confidence)/1000)
            z_precision = normal_z_score_two_tailed(p_precision)
            """
            x_from, x_to = binomial_distribution_two_tailed_range(n=sample_size, p=prob, sds=z_precision)
            xs = range(x_from, x_to+1)

            CIs = [self.method(x, sample_size, confidence) for x in xs]

            # int constructor could be used, but longdouble is used to provide better precision
            covered = [longdouble(CI[0] < prob < CI[1]) for CI in CIs]

            # multiplied by 100 in-place for better progress bar, and for a better figure later
            thiscoverage = sum(
                [covered[i]*binomial_distribution.pmf(xs[i], sample_size, prob) for i in range(len(xs))]
            ) * 100

            coverage.append(thiscoverage)

            t.set_description(progress_bar_str.format(
                f"{prob:{p_str_len}}",
                f"{thiscoverage:{cov_str_len_total}.{cov_str_len_afterpoint}f}"))

        self.coverage = coverage
        t.set_description(progress_bar_str.format(
            "*", "*", f"{self.average_coverage:{cov_str_len_total}.{cov_str_len_afterpoint}f}"))
        print(f"average confidence level {self.average_coverage:{cov_str_len_total}.{cov_str_len_afterpoint}f}")
        print(f"average deviation from {float_to_str(self.confidence*100)}% = {self.average_deviation:{cov_str_len_total}.{cov_str_len_afterpoint}f} (coverage %)")
        print("")
        return self.coverage


    def plot_coverage(self,
                    plt_figure_title: str,
                    title: str = "Coverage of {method_name}\nsample size: n = {sample_size}",
                    xlabel: str = "True Proportion (Population Proportion)",
                    ylabel: str = "Coverage (%) for {confidence_percent}%CI",
                    theme: plot_styles = "default",
                    plot_color: str = "green",
                    line_color: str = "orange"
                    ):
        """
        Plots the `matplotlib.pyplot` figure given the data from previous coverage calculation and
        some captions and formatting.
        """
        if not self.coverage: raise NoCoverageException(
            "you have to calculate coverage first before plotting it")

        confidence_percent = Decimal(self.confidence*100)

        # 2 more chars than the `confidence` str representation is enough for displaying coverage
        cov_str_len_total = max(len(str(self.confidence))+2, 5)
        # 3 characters are reserved: 2 for tens and units, 1 for point
        cov_str_len_afterpoint = max(cov_str_len_total-3, 2)

        # this unpacked defaultdict trouble allows for optional formatting placeholders
        title = title.format(**defaultdict(str, 
            method_name = self.method_name,
            sample_size = self.sample_size
        ))
        ylabel = ylabel.format(**defaultdict(str, 
            confidence_percent = float_to_str(confidence_percent)
        ))


        plt.style.use(theme)

        fig = plt.figure(plt_figure_title)

        plt.plot(list(self.proportions), self.coverage,
                 color=plot_color, marker=',', linestyle='solid', zorder=5)
        plt.axhline(float(confidence_percent),
                    color=line_color, linestyle=":", zorder=0)
        x1, x2, y1, y2 = plt.axis()
        # set vertical bondaries: from a point 10 times farther from 100 than `confidnece`, to 100
        y_min = 100-((100-confidence_percent)*10)
        plt.axis((x1, x2, y_min, 100))

        plt.title(title, fontsize="large", fontweight="bold")
        plt.xlabel(xlabel)
        plt.ylabel(ylabel)

        x1, x2, y1, y2 = plt.axis()
        # on the range (x1, x2) (left to right), the caption is centered in the middle
        # on the range (y1, y2) (bottom to top), the caption is on 1/10 of the way from y1 to y2
        plt.text(x = (x1+x2)/2,
                 y = y1 + (y2-y1)/10,
            s=f"average deviation from {float_to_str(float(confidence_percent))}% point = {self.average_deviation:{cov_str_len_total}.{cov_str_len_afterpoint}f} (coverage %)",
            ha="center", fontstyle="italic", fontsize=10, zorder=10)
        plt.xticks(fontsize=8)
        plt.ticklabel_format(scilimits=(-3,3), useMathText=True)

        self.figure = fig
        return fig


    def calculate_coverage_and_show_plot(self,
                                        sample_size: int,
                                        proportions: Iterable[float64],
                                        confidence: float,

                                        plt_figure_title: str = "",
                                        title: str = "Coverage of {method_name}\nsample size: n = {sample_size}",
                                        xlabel: str = "True Proportion (Population Proportion)",
                                        ylabel: str = "Coverage (%) for {confidence_percent}%CI",
                                        theme: plot_styles = "default"
                                        ):
        self.calculate_coverage_analytically(sample_size, proportions, confidence)
        self.plot_coverage(plt_figure_title, title, xlabel, ylabel, theme)
        self.show_plot()

